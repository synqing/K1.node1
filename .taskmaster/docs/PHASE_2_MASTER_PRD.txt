# PHASE 2: PARALLEL SWARM EXECUTION - MASTER PRD

---

## AGENT-SPECIFIC CONTEXT APPENDICES

**Each agent MUST read their assigned appendix before starting work:**

- **Agent A (Firmware):** `.taskmaster/docs/appendices/agent_a_firmware_context.md`
  - ESP32-S3 architecture constraints, critical fix patterns, performance budgets, hardware validation protocols

- **Agent B (Graph System):** `.taskmaster/docs/appendices/agent_b_graph_context.md`
  - 35-40 node taxonomy, code generation pipeline, stateful node implementation, pattern migration reference (Bloom + Spectrum)

- **Agent C (QA/Validation):** `.taskmaster/docs/appendices/agent_c_testing_context.md`
  - Hardware testing protocols (boot cycles, stress, temperature), test pyramid, regression checklist, decision gate evidence package

- **Agent D (Integration):** `.taskmaster/docs/appendices/agent_d_integration_context.md`
  - Webapp architecture, Path A UI (ReactFlow graph editor), Path B UI (parameter editor), real-time communication patterns

- **Orchestrator (Multi-Agent Coordination):** `.taskmaster/docs/appendices/agent_assignment_coordination.md`
  - Task assignment matrix, workload balancing, parallel execution map, resource conflict resolution, communication protocol, decision gate handoff

---

## EXECUTIVE SUMMARY

**Objective:** Build production-ready node graph system + AI-powered creative features (Phase C + PF-5) with multi-agent parallel execution across 30 weeks.

**Market Opportunity:** $100-150M TAM (node system is core USP; AI features unlock marketplace)

**Timeline Compression:** Parallel workstreams compress 24-week sequential plan to 20-week critical path

**Decision Gate:** Nov 13, 9 AM (Graph PoC validation) determines Path A (Graph System, 8w) vs Path B (C++ SDK, 10w)

**Team Allocation:** 4 core engineers + 1 orchestrator
- Engineer A: Firmware Security (C++, ESP32, security hardening)
- Engineer B: Graph System Architect (TypeScript, code generation, architecture)
- Engineer C: QA/Validation (Hardware testing, profiling, integration testing)
- Engineer D: Integration Engineer (TypeScript, React, API design, marketplace)
- Orchestrator: Multi-Agent Coordinator (Project management, decision gates, resource allocation)

---

## AGENT ROLE DEFINITIONS

### Agent A: Firmware Security Engineer
**Skills:** C++, ESP32, security protocols, performance optimization
**Primary Responsibility:** Phase 2D1 critical fixes, node system architecture validation, firmware hardening
**Workstreams:** Workstream A (Weeks 1-2), Workstream B architecture support
**Parallel Capacity:** High - can work independently while B & D build higher-level systems
**Blockers Outbound:** Firmware fixes block subsequent hardware validation tasks
**Depends On:** None (Week 1 starts independently)

### Agent B: Graph System Architect
**Skills:** TypeScript, Codegen, System design, Performance profiling
**Primary Responsibility:** Graph PoC validation, conditional path determination, code generation infrastructure
**Workstreams:** Workstream B (Weeks 1-2), then Path A OR Path B (Weeks 3+)
**Parallel Capacity:** Medium - PoC work is independent, but Path A/B is sequential
**Blockers Outbound:** PoC validation blocks decision gate; path choice gates entire Phase 2 strategy
**Depends On:** Agent A firmware fixes (for PoC testing), Agent C validation results

### Agent C: QA/Validation Engineer
**Skills:** Hardware testing, performance profiling, integration testing, stress testing
**Primary Responsibility:** Validate all workstreams (A, B, D), measure decision gate criteria, regression testing
**Workstreams:** Workstream C (Weeks 1-2), then continuous validation through Phase 2
**Parallel Capacity:** Very high - can test multiple workstreams simultaneously
**Blockers Outbound:** Validation reports gate decision, quality gates gate deployments
**Depends On:** Agent A & B deliverables (fixes and PoC for testing)

### Agent D: Integration Engineer
**Skills:** TypeScript, React, API design, Marketplace architecture
**Primary Responsibility:** Webapp integration, conditional path implementation (UI for Path A or Path B), marketplace setup
**Workstreams:** Conditional activation after Nov 13 decision gate
**Parallel Capacity:** Medium - starts Week 3, heavy work Weeks 3-8
**Blockers Outbound:** UI integration blocks Phase 2D1 validation, marketplace blocks PF-5 revenue
**Depends On:** Decision gate outcome (Path A or Path B selection)

### Orchestrator: Multi-Agent Coordinator
**Skills:** Project management, architecture, decision-making, risk management
**Primary Responsibility:** Monitor all workstreams, enforce dependencies, manage decision gates, allocate resources
**Workstreams:** Continuous oversight of A, B, C, D
**Parallel Capacity:** N/A - meta-level role
**Key Actions:**
- Daily standup coordination (15 min)
- Weekly risk review (1 hour)
- Decision gate preparation (Nov 13)
- Path activation (post-decision)

---

## WORKSTREAM A: PHASE 2D1 CRITICAL FIXES (WEEK 1)

**Purpose:** Prove firmware stability and security posture are production-ready before Phase 2 investment

**Assigned To:** Agent A (Firmware Security Engineer)
**Duration:** 20 hours
**Deliverable Deadline:** Nov 11, 6 PM
**Success Criteria:** All 4 fixes complete, validated, zero regressions

### Task A.1: Remove WiFi Credentials
**Assigned To:** Agent A
**Duration:** 2 hours
**Dependencies:** NONE (can start immediately)
**Parallel With:** A.3, A.4, B.1 (no resource conflicts)
**Blocks:** C.1 (Hardware validation requires secure build)
**Success Criteria:**
- WiFi credentials removed from source code
- Provisioning flow implemented (certificate-based)
- Security scan shows 0 embedded secrets
**Test Strategy:**
- Codebase scan for hardcoded strings (grep, static analysis)
- Build succeeds without credentials
- Device connects via provisioning
- Security audit approved

### Task A.2: Codegen ADR Decision
**Assigned To:** Agent A
**Duration:** 2 hours
**Dependencies:** A.1 (context needed for ADR)
**Parallel With:** A.3, A.4
**Blocks:** None (reference document, not blocking)
**Success Criteria:**
- ADR-0003 drafted (decision record)
- Team consensus on approach (sync required)
- Documented in docs/02-adr/
**Test Strategy:** Technical review consensus

### Task A.3: Fix I2S Audio Timeout
**Assigned To:** Agent A
**Duration:** 1 hour
**Dependencies:** NONE
**Parallel With:** A.1, A.4, B.1
**Blocks:** C.2 (Stress testing requires timeout protection)
**Success Criteria:**
- I2S driver timeout protection implemented
- Error codes logged properly
- No hanging during stress
**Test Strategy:**
- 1000-iteration stress test (100+ patterns)
- No timeout errors logged
- Audio pipeline responsive under load

### Task A.4: WebServer Bounds Checking
**Assigned To:** Agent A
**Duration:** 2 hours
**Dependencies:** NONE
**Parallel With:** A.1, A.3, B.1
**Blocks:** C.1 (Security validation requires bounds checking)
**Success Criteria:**
- All buffer operations bounds-checked
- Overflow protection verified
- Memory-safe code review approved
**Test Strategy:**
- Fuzzing input vectors (1000+ patterns, edge cases)
- No buffer overflows detected
- Memory profiler shows no heap corruption

### Task A.5: Error Code Registry
**Assigned To:** Agent A
**Duration:** 4 hours
**Dependencies:** A.1, A.3, A.4 (context from all fixes)
**Parallel With:** None (final integration task)
**Blocks:** C.1 (Error validation depends on this)
**Success Criteria:**
- Comprehensive error registry created (50+ codes)
- Error reporting middleware integrated
- API documented
**Test Strategy:**
- Error injection for 100% code coverage
- Proper error codes returned for all failure modes
- Telemetry collection validated

---

## WORKSTREAM B: GRAPH SYSTEM POC VALIDATION (WEEKS 1-2)

**Purpose:** Prove graph system is technically viable before committing to 8-week Path A investment

**Assigned To:** Agent B (Graph System Architect)
**Duration:** 28 hours
**Deliverable Deadline:** Nov 12, 6 PM
**Success Criteria:** PoC converts 2 patterns, FPS impact <2%, memory <5KB per node, code quality >80%

### Task B.1: Graph Architecture & Compiler Design
**Assigned To:** Agent B
**Duration:** 8 hours
**Dependencies:** NONE
**Parallel With:** A.1, A.3, A.4, C.1 (independent work)
**Blocks:** B.2, B.3, B.4 (architecture gates implementation)
**Success Criteria:**
- Node type system designed (35-40 types)
- C++ codegen algorithm specified
- State management approach documented
- Team consensus on architecture
**Test Strategy:**
- Design review (team consensus required)
- Pseudocode walkthrough
- Viability assessment passed

### Task B.2: Bloom Pattern Conversion
**Assigned To:** Agent B
**Duration:** 16 hours
**Dependencies:** B.1 (architecture must be finalized)
**Parallel With:** A.1, A.3, A.4, C.1 (Agent B primary task)
**Blocks:** B.5 (memory profiling needs this)
**Success Criteria:**
- Bloom pattern converted to graph representation
- Generated C++ code compiles without warnings
- Visual output matches original
- Performance within budget (FPS <2% impact)
**Test Strategy:**
- Visual comparison: original vs generated on device
- FPS measurement: 60 FPS baseline vs generated
- Memory profiling: per-node usage measured
- Code quality: complexity scoring >80%

### Task B.3: Spectrum Pattern Conversion
**Assigned To:** Agent B
**Duration:** 12 hours
**Dependencies:** B.1 (architecture)
**Parallel With:** B.2 (sequential on same engineer, B.2 → B.3)
**Blocks:** B.5 (memory profiling needs this)
**Success Criteria:**
- Spectrum pattern converted to graph representation
- Generated C++ code compiles without warnings
- Visual output matches original
- Performance within budget
**Test Strategy:**
- Visual comparison: original vs generated
- FPS measurement vs baseline
- Memory profiling: per-node usage
- Code quality scoring

### Task B.4: Stateful Node Implementation
**Assigned To:** Agent B
**Duration:** 12 hours
**Dependencies:** B.1 (architecture)
**Parallel With:** None (critical path for state validation)
**Blocks:** B.5 (state must be validated before profiling)
**Success Criteria:**
- Stateful node types implemented (beat detector, spectrum, etc.)
- State persistence working correctly
- Audio-reactive outputs working
- Memory overhead <1KB per node
**Test Strategy:**
- Audio input validation (beat detection accuracy >85%)
- State persistence verification
- Memory measurement with state
- Visual validation: audio-reactive output quality

### Task B.5: Memory & Performance Profiling
**Assigned To:** Agent B
**Duration:** 8 hours
**Dependencies:** B.2, B.3, B.4 (needs all implementations to profile)
**Parallel With:** None (final validation task)
**Blocks:** Decision gate (profiling determines PoC pass/fail)
**Success Criteria:**
- Memory per node < 5KB (target budget)
- Compilation time < 2 seconds
- FPS impact < 2% (measured)
- Code quality report > 80%
- Device latency < 10ms
**Test Strategy:**
- Profiler: heap memory measurement
- Timing: build time capture
- FPS: live device measurement (60 FPS baseline)
- Latency: frame timing analysis
- Quality: complexity + readability scoring

---

## WORKSTREAM C: QA & VALIDATION (WEEKS 1-2)

**Purpose:** Validate all fixes and PoC components meet production standards

**Assigned To:** Agent C (QA/Validation Engineer)
**Duration:** 14 hours
**Deliverable Deadline:** Nov 13, 8 AM
**Success Criteria:** All 6 decision gate criteria validated and documented

### Task C.1: Hardware Validation Testing
**Assigned To:** Agent C
**Duration:** 4 hours
**Dependencies:** A.1, A.4 (security fixes needed for testing)
**Parallel With:** B.1, B.2 (test is independent)
**Blocks:** Decision gate (hardware validation required)
**Success Criteria:**
- Device boots reliably (100 cold boots, 0 hangs)
- Memory usage stable (baseline + 5% margin)
- No crashes in 24-hour continuous run
**Test Strategy:**
- 100x boot cycle test
- Memory monitoring over 24 hours
- Error logging review (0 critical errors)
- Hardware-specific edge cases tested

### Task C.2: Stress Testing & Stability
**Assigned To:** Agent C
**Duration:** 8 hours
**Dependencies:** A.3 (timeout fix required)
**Parallel With:** B.2, B.3 (independent testing)
**Blocks:** Decision gate (stability required)
**Success Criteria:**
- 1000+ pattern changes without crashes
- All 15 hardcoded patterns stress-tested
- WiFi reconnection working (10x cycle)
- Temperature stable under load
**Test Strategy:**
- Automated pattern cycling (1000 iterations)
- WiFi reconnect testing (10x)
- Temperature monitoring
- Memory leak detection (valgrind equivalent)
- Error log analysis (0 crashes)

### Task C.3: Code Quality & Coverage Review
**Assigned To:** Agent C
**Duration:** 2 hours
**Dependencies:** A.1, A.2, A.3, A.4, B.5 (all code complete)
**Parallel With:** None (final review task)
**Blocks:** Decision gate (quality gates required)
**Success Criteria:**
- Test coverage >= 95%
- 0 high-severity static analysis warnings
- Code review consensus passed
- ADR documentation complete
**Test Strategy:**
- Coverage measurement (lcov, pytest)
- Static analysis (clang-tidy, cppcheck)
- Code review (team consensus required)
- ADR quality review

---

## DECISION GATE: WEEK 2 END (NOV 13, 9:00 AM)

**Purpose:** Determine execution path for Phase 2 (Graph System vs C++ SDK)

**Criteria Validation:**
1. ✅ Phase 2D1 complete + validated (A.1, A.2, A.3, A.4, A.5)
2. ✅ FPS impact < 2% (B.5 measured)
3. ✅ Memory < 5KB per node (B.5 measured)
4. ✅ Stability: 24h run, 0 crashes (C.1, C.2)
5. ✅ Code quality: 0 warnings, >= 95% coverage (C.3)
6. ✅ Compile < 5s, device latency < 10ms (B.5 measured)

**Decision Outcomes:**

### IF ALL CRITERIA PASS → PATH A: GRAPH SYSTEM (8-WEEK EXECUTION)
- Activate tasks tagged [PATH_A]
- Deactivate tasks tagged [PATH_B]
- Activate Agent D (Integration Engineer) for Graph UI
- Timeline: Weeks 3-8 (Jan 15 ship)
- Resource: 4 engineers (A, B, C, D)
- Revenue potential: $100-150M+

### IF ANY CRITERIA FAIL → PATH B: C++ SDK (10-WEEK EXECUTION)
- Activate tasks tagged [PATH_B]
- Deactivate tasks tagged [PATH_A]
- Scale back Agent D (minimal UI improvements)
- Timeline: Weeks 3-10 (Jan 29 ship)
- Resource: 3 engineers (A, B, C)
- Revenue potential: $50-100M

---

## WORKSTREAM D: CONDITIONAL EXECUTION (WEEKS 3-14)

### PATH A: GRAPH SYSTEM FULL IMPLEMENTATION [TAG: PATH_A]

**Prerequisites:**
- decision-gate-passed = true
- graph-system-poc-validated = true

#### Phase C.1: Extend Codegen for Stateful Nodes
**Assigned To:** Agent B
**Duration:** 24 hours
**Dependencies:** B.5 (PoC architecture)
**Parallel With:** D.1, D.2
**Blocks:** D.4, D.5 (webapp integration needs this)
**Success Criteria:**
- Codegen handles 35-40 node types
- Stateful nodes compile correctly
- Performance validated (< 1KB per node)
- Code generation time < 2s

#### Phase C.2: Migrate 8-10 High-Value Patterns
**Assigned To:** Agent B
**Duration:** 40 hours
**Dependencies:** D.1 (codegen extended)
**Sequential With:** Migration patterns (each depends on previous)
**Blocks:** D.4 (UI integration needs patterns)
**Success Criteria:**
- 8-10 patterns converted to graphs
- All patterns compile + run on device
- Visual output matches hardcoded versions
- FPS impact < 2% for all patterns

#### Phase C.3: Webapp Graph UI Integration
**Assigned To:** Agent D
**Duration:** 16 hours
**Dependencies:** D.1, D.2 (codegen and patterns complete)
**Parallel With:** D.6 (Agent D primary task)
**Blocks:** D.5 (testing needs UI)
**Success Criteria:**
- Canvas editor working with 50+ nodes
- Graph → JSON serialization working
- Node palette complete (35-40 types)
- Real-time validation feedback

#### Phase C.4: Graph System Integration Testing
**Assigned To:** Agent C
**Duration:** 16 hours
**Dependencies:** D.1, D.2, D.3 (all pieces complete)
**Parallel With:** D.6, D.7 (testing phase)
**Blocks:** Phase 2 completion
**Success Criteria:**
- End-to-end graph creation → compilation → device
- 100+ patterns created and tested
- No regressions vs hardcoded versions
- Performance targets met

### PATH B: C++ SDK FORMALIZATION [TAG: PATH_B]

**Prerequisites:**
- decision-gate-passed = true
- graph-system-poc-failed = true

#### Phase B.1: SDK Documentation & Templates
**Assigned To:** Agent B
**Duration:** 16 hours
**Dependencies:** A.5 (error registry needed for docs)
**Parallel With:** D.7 (independent work)
**Blocks:** D.8, D.9 (UI depends on SDK API)
**Success Criteria:**
- Complete SDK documentation (API reference, examples)
- 5+ example patterns (well-documented)
- Integration guide for external developers
- Parameter schema documented

#### Phase B.2: Parameter Editor Design
**Assigned To:** Agent B
**Duration:** 24 hours
**Dependencies:** D.7 (SDK docs needed)
**Sequential With:** D.7 → D.8
**Blocks:** D.9 (UI integration needs this)
**Success Criteria:**
- Parameter editor UI designed
- Real-time preview working
- Validation for all parameters
- Intuitive controls for non-technical users

#### Phase B.3: Webapp SDK Integration
**Assigned To:** Agent D
**Duration:** 16 hours
**Dependencies:** D.8 (parameter editor complete)
**Parallel With:** D.10 (integration phase)
**Blocks:** D.10 (testing needs UI)
**Success Criteria:**
- Parameter editor integrated into webapp
- Device communication working
- Real-time pattern updates
- Error handling + user feedback

#### Phase B.4: SDK Integration Testing
**Assigned To:** Agent C
**Duration:** 16 hours
**Dependencies:** D.7, D.8, D.9 (all pieces complete)
**Parallel With:** D.10 (testing phase)
**Blocks:** Phase 2 completion
**Success Criteria:**
- SDK parameter constraints validated
- Device communication reliability (99.5% uptime)
- 100+ parameter combinations tested
- User experience validated

---

## TASK DEPENDENCY MATRIX

```
Week 1:
├── A.1 (2h)    → C.1 (4h)
├── A.3 (1h)    → C.2 (8h)
├── A.4 (2h)    → C.1 (4h)
├── A.2 (2h)    → (reference only, no blockers)
├── A.5 (4h)    ← A.1, A.3, A.4 (all must complete)
│
├── B.1 (8h)    → B.2 (16h) + B.3 (12h) + B.4 (12h)
├── B.2 (16h)   → B.5 (8h)
├── B.3 (12h)   → B.5 (8h)
├── B.4 (12h)   → B.5 (8h)
└── B.5 (8h)    → DECISION GATE

Week 2:
└── C.1, C.2, C.3 (all depend on Week 1 completions)

Decision Gate (Nov 13):
├── IF PASS → PATH A tasks [D.1-D.4]
└── IF FAIL → PATH B tasks [D.5-D.8]
```

---

## SUCCESS CRITERIA SUMMARY

**Week 1 (Nov 6-13):**
- ✅ All 5 Phase 2D1 fixes complete
- ✅ Graph PoC validates 2 patterns
- ✅ FPS impact < 2%, memory < 5KB/node
- ✅ 24-hour stability run: 0 crashes
- ✅ Code quality: >= 95% coverage, 0 warnings
- ✅ Decision gate criteria measured

**Week 2-8 Path A (IF Graph System):**
- ✅ Phase C complete (Node Graph Editor)
- ✅ 8-10 patterns migrated to graphs
- ✅ Webapp UI fully functional
- ✅ 100+ test patterns created and validated
- ✅ Performance maintained (FPS < 2% impact)

**Week 2-10 Path B (IF C++ SDK):**
- ✅ SDK documented and released
- ✅ Parameter editor functional
- ✅ 100+ parameter combinations validated
- ✅ Integration testing complete

**Phase 2 Completion (Week 14-20):**
- ✅ Full PF-5 integration (audio, color, language, personalization)
- ✅ Marketplace live with artist onboarding
- ✅ WCAG 2.1 AA compliance verified
- ✅ Photosensitivity validation complete
- ✅ Load testing: 1000 concurrent users, <100ms p95 latency
- ✅ Ship date met (Jan 15 Path A or Jan 29 Path B)

---

## ESTIMATED EFFORT

| Workstream | Agent | Hours | Weeks | Critical |
|-----------|-------|-------|-------|----------|
| **A: Phase 2D1** | A | 20 | 1 | YES |
| **B: Graph PoC** | B | 28 | 1-2 | YES |
| **C: QA/Validation** | C | 14 | 1-2 | YES |
| **Decision Gate** | All | - | Week 2 | YES |
| **Path A (if go)** | A,B,D | 350+ | 5 | YES |
| **Path B (if no-go)** | A,B,D | 400+ | 7 | YES |
| **Total Phase 2** | 4 eng | 800+ | 20-26 weeks | YES |

---

## RESOURCE ALLOCATION

| Agent | Week 1-2 | Path A (Weeks 3-8) | Path B (Weeks 3-10) |
|-------|----------|-------------------|-------------------|
| **A: Firmware** | 20h (fixes) | Parallel fixes + optimization | Optimization + stability |
| **B: Graph Arch** | 28h (PoC) | 64h (codegen + migration) | 40h (SDK docs + editor) |
| **C: QA** | 14h (validation) | 40h+ (continuous) | 40h+ (continuous) |
| **D: Integration** | STANDBY | 40h+ (Graph UI) | 40h+ (Parameter UI) |

---

## CONTACT & ESCALATION

**Workstream A Owner:** Agent A (Firmware Security Engineer)
**Workstream B Owner:** Agent B (Graph System Architect)
**Workstream C Owner:** Agent C (QA/Validation Engineer)
**Decision Gate Owner:** Orchestrator (Multi-Agent Coordinator)
**Path Activation:** Engineering Lead + CEO (final decision)

---

**PRD Status:** READY FOR TASKMASTER PARSING
**Target Parse Date:** 2025-11-05 12:42 UTC+8
**Expected Task Count:** 20-25 top-level tasks, 50-70 subtasks
**Decision Gate Date:** 2025-11-13 09:00 UTC+8

---

## DOCUMENTATION STANDARDS

All project documentation and task tracking must adhere to these timestamp standards:

**Date Format:** ISO 8601 (YYYY-MM-DD)
**Timestamp Format:** HH:MM UTC+8 (24-hour format, Taiwan Standard Time)
**Combined Format:** `YYYY-MM-DD HH:MM UTC+8`

**Where Required:**
- CHANGELOG.md entries (all version releases)
- Front-matter metadata in all documents (author, date, status, intent)
- TaskMaster task dates and deadline tracking
- Decision gate records and meeting minutes
- Commit messages referencing specific decision points
- Technical specification documents with implementation timelines

**Purpose:** Ensure precise chronological ordering and decision traceability across distributed teams during 30-week parallel execution
